{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ccRet0cT8Gpz"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",(package)])\n",
        "\n",
        "def freeze_requirements():\n",
        "    try:\n",
        "        with open('requirements.txt', 'w') as f:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"freeze\"], stdout=f)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Failed to freeze requirements: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahlhCNbz8Gp1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "packages = [\"numpy\",\"pandas\",\"matplotlib\",\"seaborn\",\"scikit-learn\"]\n",
        "\n",
        "for pkg in packages:\n",
        "    install(pkg)\n",
        "\n",
        "freeze_requirements()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWeDm5bV8Gp2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "PROJECT_ROOT_DIR = \"include/\"\n",
        "FOLDER_NAME = \"CarPriceDataset_Final\"\n",
        "import_csv_through_url = 'https://raw.githubusercontent.com/Sudipta1975git/Car_Price_dataset/main/CarPriceDataset_Final.csv'\n",
        "HOUSING_PATH = os.path.join(PROJECT_ROOT_DIR+\"datasets\",FOLDER_NAME)\n",
        "os.makedirs(HOUSING_PATH, exist_ok=True)\n",
        "\n",
        "car_price_url = PROJECT_ROOT_DIR+\"datasets\"+FOLDER_NAME+\"\"\n",
        "# df_url = pd.read_csv(import_csv_through_url)\n",
        "\n",
        "# File path to save the downloaded CSV\n",
        "local_csv_path = os.path.join(HOUSING_PATH, \"CarPriceDataset_Final.csv\")\n",
        "df = pd.read_csv(import_csv_through_url)\n",
        "df.to_csv(local_csv_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE2F2cP68Gp2"
      },
      "outputs": [],
      "source": [
        "data_root = \"https://github.com/ageron/data/raw/main/\"\n",
        "lifesat = pd.read_csv(data_root + \"lifesat/lifesat.csv\")\n",
        "# lifesat.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeuFF1A-8Gp2"
      },
      "outputs": [],
      "source": [
        "X = lifesat[[\"GDP per capita (USD)\"]].values\n",
        "y = lifesat[[\"Life satisfaction\"]].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNkMrCAg8Gp3"
      },
      "outputs": [],
      "source": [
        "# X = pd.DataFrame([1,2,3,4,5,6])\n",
        "\n",
        "# y = pd.DataFrame([11,12,13,14,15,16])\n",
        "\n",
        "def mean(arr):\n",
        "    length = len(arr)\n",
        "    # print(length)\n",
        "    sum = 0\n",
        "    for a in range(0,length):\n",
        "        sum = sum + arr[a]\n",
        "    mean_val =  sum/length\n",
        "\n",
        "    return mean_val\n",
        "\n",
        "def variance(x):\n",
        "\n",
        "    length = len(x)\n",
        "    mean_value = mean(x)\n",
        "    variance_sum = 0\n",
        "    for a in range(0,length):\n",
        "        variance_sum = variance_sum +(((x[a]) - mean_value)**2)\n",
        "    variance_total =variance_sum/length\n",
        "    return variance_total\n",
        "\n",
        "def covariance(x, y):\n",
        "    length = len(x)\n",
        "    mean_x = mean(x)\n",
        "    mean_y = mean(y)\n",
        "    cov_sum = 0\n",
        "    for i in range(0, length):\n",
        "        cov_sum += (x[i] - mean_x) * (y[i] - mean_y)\n",
        "    return cov_sum / length\n",
        "\n",
        "def slope(x,y):\n",
        "    return covariance(x,y)/variance(x)\n",
        "\n",
        "def intercept(x,y,slope):\n",
        "    return mean(y) - slope * mean(x)\n",
        "\n",
        "def predict(x, slope, intercept):\n",
        "\n",
        "    return slope * x + intercept\n",
        "\n",
        "slope_value = slope(X,y)\n",
        "intercept_value = intercept(X,y,slope_value)\n",
        "\n",
        "print(f\"Slope: {slope_value}\")\n",
        "print(f\"Intercept: {intercept_value}\")\n",
        "\n",
        "new_val = 37_655.2\n",
        "\n",
        "predictions = predict(new_val,slope_value,intercept_value)\n",
        "print(f\"Predictions: {predictions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KlmgM6_8Gp4"
      },
      "outputs": [],
      "source": [
        "data_root"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncoqfYxD8Gp4"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X,y)\n",
        "\n",
        "new_val = np.array([[new_val]])\n",
        "print(model.predict(new_val))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf6adIGM8Gp6"
      },
      "source": [
        "# Hands-On Machine Learning [Chapter: 2]\n",
        "\n",
        "<h5>Housing Complex Datasheet</h5>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOx1kcrq8Gp7"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \"includes/\"\n",
        "CHAPTER_ID = \"end_to_end_project\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx-rqgcs8Gp8"
      },
      "source": [
        "\n",
        "<h3>Get the Data</h3>\n",
        "<h5>Download the Data</h5>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owmgnivO8Gp9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "HOUSING_PATH = os.path.join(PROJECT_ROOT_DIR+\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    if not os.path.isdir(housing_path):\n",
        "        os.makedirs(housing_path)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()\n",
        "    return pd.read_csv(Path(PROJECT_ROOT_DIR+\"/datasets/housing/housing.csv\"))\n",
        "\n",
        "housing = fetch_housing_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2Gm9KNQ8Gp-"
      },
      "outputs": [],
      "source": [
        "housing.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOZD0eAC8Gp_"
      },
      "outputs": [],
      "source": [
        "housing.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sgq8hcdI8GqA"
      },
      "outputs": [],
      "source": [
        "housing['ocean_proximity'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZYykuvZ8GqB"
      },
      "outputs": [],
      "source": [
        "housing.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiHBd2OP8GqB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "housing.hist(bins=50,figsize=(12,8))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def split_train_test(data, test_ratio):\n",
        "    shuffled_indices = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data) * test_ratio)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    return data.iloc[train_indices], data.iloc([test_indices])"
      ],
      "metadata": {
        "id": "HBv-ZufLzgRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zlib import crc32\n",
        "\n",
        "def is_id_in_test_set(identifier, test_ratio):\n",
        "  return crc32(np.int64(identifier)) < test_ratio * 2**32\n",
        "\n",
        "def split_data_with_id_hash(data, test_ratio, id_column):\n",
        "  ids = data[id_column]\n",
        "  in_test_set = ids.apply(lambda id: is_id_in_test_set(id, test_ratio))\n",
        "  return data.loc[~in_test_set], data.loc[in_test_set]\n",
        "\n"
      ],
      "metadata": {
        "id": "-f2N3o7JE_h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_with_id = housing.reset_index()\n",
        "train_set, test_set = split_data_with_id_hash(housing_with_id, 0.2, \"index\")\n",
        "\n",
        "print(\"Training length: \",len(train_set))\n",
        "print(\"Test length: \",len(test_set))"
      ],
      "metadata": {
        "id": "6lzEapVGa1ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing['income_cat'] = pd.cut(housing['median_income'],bins=[0.,1.5,3.0,4.5,6.,np.inf],labels=[1,2,3,4,5])\n",
        "housing['income_cat'].value_counts().sort_index().plot.bar(rot=0,grid=True)\n",
        "plt.xlabel(\"Income Category\")\n",
        "plt.ylabel(\"Number of Districts\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i7KZtMXQmIfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# splitter = StratifiedShuffleSplit(n_splits=10,test_size=0.2,random_state=42)\n",
        "# strat_splits = []\n",
        "# for train_index, test_index in splitter.split(housing,housing['income_cat']):\n",
        "#     strat_train_set = housing.loc[train_index]\n",
        "#     strat_test_set = housing.loc[test_index]\n",
        "#     strat_splits.append((strat_train_set,strat_test_set))"
      ],
      "metadata": {
        "id": "werG3_bYUFI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strat_train_set, strat_test_set = train_test_split(housing, test_size=0.2, stratify = housing['income_cat'],random_state=42)"
      ],
      "metadata": {
        "id": "IUWLc99hcW5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strat_test_set['income_cat'].value_counts()/len(strat_test_set)"
      ],
      "metadata": {
        "id": "-J0xQlLwcpme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for set_ in (strat_test_set,strat_train_set):\n",
        "  set_.drop('income_cat',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "PibIvlvqc6-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Data Visualization"
      ],
      "metadata": {
        "id": "Is_J22sDkC29"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnIkJsgQ0UVK"
      },
      "outputs": [],
      "source": [
        "housing = strat_train_set.copy()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}